{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Text clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is about categorizing/organizing/labelling objects such as to maximize the similarity between objects in one cluster/group (inner class similarity) while maximazing the dissimilarity between different clusters (inter class similarity).\n",
    "\n",
    "Clustering is an example of an unsupervised learning algorithm.\n",
    "\n",
    "In the following cells I will explore clustering related to text/sentences. In such context similarity should target the semantic and pragmatic meaning of the text: sentences with the same or closely similar meaning should fall into the same category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T16:42:54.944833",
     "start_time": "2017-08-31T16:42:54.929832"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools \n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T16:37:15.662427",
     "start_time": "2017-08-31T16:37:15.637425"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A brown fox jumped on the lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A brown fox jumped on the brown duck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A brown fox jumped on the lazy elephant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An elephant is eating green grass near the alpaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A green alpaca tried to jump over an elephant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>May you rest in a deep and dreamless slumber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences\n",
       "0                 A brown fox jumped on the lazy dog\n",
       "1               A brown fox jumped on the brown duck\n",
       "2            A brown fox jumped on the lazy elephant\n",
       "3  An elephant is eating green grass near the alpaca\n",
       "4      A green alpaca tried to jump over an elephant\n",
       "5       May you rest in a deep and dreamless slumber"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy example data.\n",
    "vocabulary_size = 1000\n",
    "sentences = [\"A brown fox jumped on the lazy dog\", \n",
    "            \"A brown fox jumped on the brown duck\",\n",
    "            \"A brown fox jumped on the lazy elephant\",\n",
    "            \"An elephant is eating green grass near the alpaca\",\n",
    "            \"A green alpaca tried to jump over an elephant\",\n",
    "            \"May you rest in a deep and dreamless slumber\"]\n",
    "df = pd.DataFrame(sentences, columns=['sentences'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common ways to vectorize your sentences are based on words count. \n",
    "Each sentence is represented by a vector of length N, where N is the size of your vocabulary. Each element of the vector is then associated with a word (or N-gram), and has a value that depends on the technique used for the vectorization.\n",
    "* count\n",
    "* tf-idf (term frequency * inverse term frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T16:37:20.699715",
     "start_time": "2017-08-31T16:37:20.695715"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T16:37:29.462216",
     "start_time": "2017-08-31T16:37:29.452215"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This class accepts functions for preprocessing and tokenization, \n",
    "# so you can operate your data cleaning directly at this point.\n",
    "vectorizer = CountVectorizer(analyzer=\"word\", max_features=vocabulary_size, stop_words=\"english\", ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(df[\"sentences\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T16:37:38.056708",
     "start_time": "2017-08-31T16:37:38.052707"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 37)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-31T16:37:40.674857",
     "start_time": "2017-08-31T16:37:40.666857"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown': 2,\n",
       " 'fox': 15,\n",
       " 'jumped': 24,\n",
       " 'lazy': 27,\n",
       " 'dog': 7,\n",
       " 'brown fox': 4,\n",
       " 'fox jumped': 16,\n",
       " 'jumped lazy': 26,\n",
       " 'lazy dog': 28,\n",
       " 'duck': 10,\n",
       " 'jumped brown': 25,\n",
       " 'brown duck': 3,\n",
       " 'elephant': 13,\n",
       " 'lazy elephant': 29,\n",
       " 'eating': 11,\n",
       " 'green': 19,\n",
       " 'grass': 17,\n",
       " 'near': 30,\n",
       " 'alpaca': 0,\n",
       " 'elephant eating': 14,\n",
       " 'eating green': 12,\n",
       " 'green grass': 21,\n",
       " 'grass near': 18,\n",
       " 'near alpaca': 31,\n",
       " 'tried': 35,\n",
       " 'jump': 22,\n",
       " 'green alpaca': 20,\n",
       " 'alpaca tried': 1,\n",
       " 'tried jump': 36,\n",
       " 'jump elephant': 23,\n",
       " 'rest': 32,\n",
       " 'deep': 5,\n",
       " 'dreamless': 8,\n",
       " 'slumber': 34,\n",
       " 'rest deep': 33,\n",
       " 'deep dreamless': 6,\n",
       " 'dreamless slumber': 9}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[4].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 2, 1], dtype=int32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify number of clusters and fit the data\n",
    "num_clusters = 3\n",
    "kmeans = KMeans(n_clusters= num_clusters)\n",
    "kmeans.fit(X)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A brown fox jumped on the lazy dog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A brown fox jumped on the brown duck</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A brown fox jumped on the lazy elephant</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An elephant is eating green grass near the alpaca</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A green alpaca tried to jump over an elephant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>May you rest in a deep and dreamless slumber</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  Cluster\n",
       "0                 A brown fox jumped on the lazy dog        0\n",
       "1               A brown fox jumped on the brown duck        0\n",
       "2            A brown fox jumped on the lazy elephant        0\n",
       "3  An elephant is eating green grass near the alpaca        2\n",
       "4      A green alpaca tried to jump over an elephant        2\n",
       "5       May you rest in a deep and dreamless slumber        1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict/retrieve the cluster ID of our data\n",
    "df['Cluster'] = kmeans.labels_\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = [\"This sentence describes a new fox\",  \"A random sentence without any animal\", \"Deep learning\"]\n",
    "new_X = vectorizer.transform(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1], dtype=int32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = kmeans.predict(new_X)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice text clustering using corrona dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4794</td>\n",
       "      <td>49746</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>17-03-2020</td>\n",
       "      <td>Connectivity is essential during times of cris...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4795</td>\n",
       "      <td>49747</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>17-03-2020</td>\n",
       "      <td>@standwithPrager Wells Fargo is committed to h...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4796</td>\n",
       "      <td>49748</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>17-03-2020</td>\n",
       "      <td>@KariLeeAK907 Wells Fargo is committed to help...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4797</td>\n",
       "      <td>49749</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>17-03-2020</td>\n",
       "      <td>@TheIndigoAuthor Wells Fargo is committed to h...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4798</td>\n",
       "      <td>49750</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>17-03-2020</td>\n",
       "      <td>@WinAtLifeOnline Rest assured that our team is...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserName  ScreenName           Location     TweetAt  \\\n",
       "0        3799       48751             London  16-03-2020   \n",
       "1        3800       48752                 UK  16-03-2020   \n",
       "2        3801       48753          Vagabonds  16-03-2020   \n",
       "3        3802       48754                NaN  16-03-2020   \n",
       "4        3803       48755                NaN  16-03-2020   \n",
       "..        ...         ...                ...         ...   \n",
       "995      4794       49746     Washington, DC  17-03-2020   \n",
       "996      4795       49747  San Francisco, CA  17-03-2020   \n",
       "997      4796       49748  San Francisco, CA  17-03-2020   \n",
       "998      4797       49749  San Francisco, CA  17-03-2020   \n",
       "999      4798       49750       San Jose, CA  17-03-2020   \n",
       "\n",
       "                                         OriginalTweet           Sentiment  \n",
       "0    @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1    advice Talk to your neighbours family to excha...            Positive  \n",
       "2    Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3    My food stock is not the only one which is emp...            Positive  \n",
       "4    Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "..                                                 ...                 ...  \n",
       "995  Connectivity is essential during times of cris...            Negative  \n",
       "996  @standwithPrager Wells Fargo is committed to h...  Extremely Positive  \n",
       "997  @KariLeeAK907 Wells Fargo is committed to help...  Extremely Positive  \n",
       "998  @TheIndigoAuthor Wells Fargo is committed to h...  Extremely Positive  \n",
       "999  @WinAtLifeOnline Rest assured that our team is...            Negative  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"Corona_NLP_train.csv\"\n",
    "train_df = pd.read_csv(train_file, encoding='latin-1')[:1000]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Extremely Negative', 'Extremely Positive', 'Negative', 'Neutral', 'Positive'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_df[\"Sentiment\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>45048</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>10-03-2020</td>\n",
       "      <td>The government must provide hand sanitizer in ...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>45049</td>\n",
       "      <td>United States</td>\n",
       "      <td>10-03-2020</td>\n",
       "      <td>What You Need If Quarantined at Home | #Corona...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>45050</td>\n",
       "      <td>Indianapolis, IN</td>\n",
       "      <td>10-03-2020</td>\n",
       "      <td>See the new @FujifilmX_US X-T4 and X100V at Ro...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>45051</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>10-03-2020</td>\n",
       "      <td>Spiking prices during a state of emergency is ...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>45052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-03-2020</td>\n",
       "      <td>Besides canned food and toilet paper.\\r\\r\\n\\r\\...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserName  ScreenName             Location     TweetAt  \\\n",
       "0          1       44953                  NYC  02-03-2020   \n",
       "1          2       44954          Seattle, WA  02-03-2020   \n",
       "2          3       44955                  NaN  02-03-2020   \n",
       "3          4       44956          Chicagoland  02-03-2020   \n",
       "4          5       44957  Melbourne, Victoria  03-03-2020   \n",
       "..       ...         ...                  ...         ...   \n",
       "95        96       45048              Ireland  10-03-2020   \n",
       "96        97       45049        United States  10-03-2020   \n",
       "97        98       45050     Indianapolis, IN  10-03-2020   \n",
       "98        99       45051        San Diego, CA  10-03-2020   \n",
       "99       100       45052                  NaN  10-03-2020   \n",
       "\n",
       "                                        OriginalTweet           Sentiment  \n",
       "0   TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
       "1   When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
       "2   Find out how you can protect yourself and love...  Extremely Positive  \n",
       "3   #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
       "4   #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  \n",
       "..                                                ...                 ...  \n",
       "95  The government must provide hand sanitizer in ...  Extremely Positive  \n",
       "96  What You Need If Quarantined at Home | #Corona...             Neutral  \n",
       "97  See the new @FujifilmX_US X-T4 and X100V at Ro...  Extremely Positive  \n",
       "98  Spiking prices during a state of emergency is ...  Extremely Negative  \n",
       "99  Besides canned food and toilet paper.\\r\\r\\n\\r\\...             Neutral  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = \"Corona_NLP_test.csv\"\n",
    "test_df = pd.read_csv(test_file, encoding='latin-1')[:100]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\", max_features=vocabulary_size, stop_words=\"english\", ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(train_df[\"OriginalTweet\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Train a Kmean algorithm using thre train data then use the trained model to cluster the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: In your opinion, is this a good result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "229px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
